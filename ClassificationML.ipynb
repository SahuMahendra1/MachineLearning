{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa9d77b6-1247-41c2-ae1d-a8e35b055e24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "079a34aa-f7bf-4fab-8284-1d6d2e427263",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data.data,columns=data.feature_names)\n",
    "df['target']=data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target',axis=1), df['target'], test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8832ace9-1773-4ab7-af2f-fd8dafc5d691",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 🧠 What Is Logistic Regression?\n",
    "\n",
    "Despite its name, logistic regression is a classification algorithm, not a regression one. It’s used to predict the probability of a binary outcome—like yes/no, spam/not spam, or disease/no disease.\n",
    "\n",
    "🔍 Key Idea\n",
    "\n",
    "Logistic regression models the probability that a given input belongs to a class using the sigmoid function:\n",
    "\n",
    "**Sigmoid Function:**\n",
    "\n",
    "$$\n",
    "sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "z = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_p x_p\n",
    "$$\n",
    "\n",
    "\n",
    "sigma(z) squashes the output to a value between 0 and 1.\n",
    "\n",
    "\n",
    "🧮 Cost Function (Log Loss)\n",
    "Instead of Mean Squared Error, logistic regression uses log loss:\n",
    "\n",
    "$$\n",
    "J(\\theta) = -\\frac{1}{n} \\sum_{i=1}^n \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right]\n",
    "$$\n",
    "Penalizes confident wrong predictions heavily\n",
    "\n",
    "Encourages the model to output probabilities close to the true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8415750-d88d-4ebc-8791-d74e343fd2a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "param=[{'C': [0.001, 0.01, 0.1, 1, 10, 100,200]},{'max_iter':[100,150]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8c664f4-62fb-43f3-b79b-8da81886a0a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=10,max_iter=100)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(model,param_grid=param,scoring='accuracy',cv=5)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df459257-ebde-4f28-a71d-702ecf4a4b7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9d3cac6-db13-406c-9213-bc7265d6f969",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(grid.best_params_,\n",
    "grid.best_score_,\n",
    "grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee651d60-5e24-4f78-9ec8-509ebe0d5602",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred = grid.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0bc0fb5-10d6-488e-b292-e73ee53ed261",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a3937a9-da2b-4bd1-a7a0-6bc64cc03122",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 📚 Naive Bayes Theorem\n",
    "Naive Bayes is based on Bayes’ Theorem, which describes the probability of a class given some features:\n",
    "\n",
    "𝑃\n",
    "(\n",
    "𝑦\n",
    "∣\n",
    "𝑥\n",
    "1\n",
    ",\n",
    "𝑥\n",
    "2\n",
    ",\n",
    ".\n",
    ".\n",
    ".\n",
    ",\n",
    "𝑥\n",
    "𝑛\n",
    ")\n",
    "=\n",
    "𝑃\n",
    "(\n",
    "𝑥\n",
    "1\n",
    ",\n",
    "𝑥\n",
    "2\n",
    ",\n",
    ".\n",
    ".\n",
    ".\n",
    ",\n",
    "𝑥\n",
    "𝑛\n",
    "∣\n",
    "𝑦\n",
    ")\n",
    "⋅\n",
    "𝑃\n",
    "(\n",
    "𝑦\n",
    ")\n",
    "𝑃\n",
    "(\n",
    "𝑥\n",
    "1\n",
    ",\n",
    "𝑥\n",
    "2\n",
    ",\n",
    ".\n",
    ".\n",
    ".\n",
    ",\n",
    "𝑥\n",
    "𝑛\n",
    ")\n",
    "\n",
    "🔹 Naive Assumption:\n",
    "It assumes that all features \n",
    "𝑥\n",
    "𝑖\n",
    " are independent given the class \n",
    "𝑦\n",
    ", so:\n",
    "\n",
    "𝑃\n",
    "(\n",
    "𝑦\n",
    "∣\n",
    "𝑥\n",
    "1\n",
    ",\n",
    "𝑥\n",
    "2\n",
    ",\n",
    ".\n",
    ".\n",
    ".\n",
    ",\n",
    "𝑥\n",
    "𝑛\n",
    ")\n",
    "∝\n",
    "𝑃\n",
    "(\n",
    "𝑦\n",
    ")\n",
    "⋅\n",
    "∏\n",
    "𝑖\n",
    "=\n",
    "1\n",
    "𝑛\n",
    "𝑃\n",
    "(\n",
    "𝑥\n",
    "𝑖\n",
    "∣\n",
    "𝑦\n",
    ")\n",
    "We predict the class \n",
    "𝑦\n",
    " that maximizes this probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3787cf1c-9dab-415f-96fc-626a19e6d2b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e4b2382-ffbf-403f-ba9b-30af6f0879ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5c0de02-b58d-4e65-85f3-a444e8d09674",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf7cb0fd-da02-4462-8cc9-9951df01a8cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "🧠 What Is Gaussian Naive Bayes?\n",
    "Gaussian Naive Bayes is a variant of the Naive Bayes classifier used when your features are continuous and assumed to follow a normal (Gaussian) distribution.\n",
    "\n",
    "📚 How It Works\n",
    "\n",
    "Naive Bayes uses Bayes’ Theorem:\n",
    "\n",
    "$$\n",
    "P(y \\mid x_1, x_2, \\ldots, x_n) \\propto P(y) \\prod_{i=1}^n P(x_i \\mid y)\n",
    "$$\n",
    "\n",
    "In GaussianNB, each $P(x_i \\mid y)$ is modeled using the Gaussian (normal) probability density function:\n",
    "\n",
    "$$\n",
    "P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi \\sigma_y^2}} \\exp\\left( -\\frac{(x_i - \\mu_y)^2}{2\\sigma_y^2} \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $$\\mu_y$$: Mean of feature xi for class y\n",
    "- $$\\sigma_y^2$$: Variance of feature xi for class y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5184c9f-66c1-4705-a971-fa20d2d2f2d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a4bd0cd-aa67-446e-bd97-41137c6afc84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 🧠 What Is K-Nearest Neighbors?\n",
    "KNN is a non-parametric, instance-based learning algorithm used for classification and regression. It makes predictions based on the k closest data points in the training set.\n",
    "\n",
    "### How It Works\n",
    "- Choose a value for k (e.g., 3 or 5).\n",
    "- For a new data point:\n",
    "- Measure the distance to all training points (usually Euclidean). \n",
    "- Find the k nearest neighbors.\n",
    "- For classification: return the most common class among neighbors.\n",
    "- For regression: return the average value of neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8858d82e-c196-4d79-99d2-03db7e8da8e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8734418-38f6-4350-9cf5-3c466584eb68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "x=iris.data\n",
    "y=iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bba63c3-5ddd-4046-a62f-e0007cc1af0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy\",accuracy_score(y_test,y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c2b5935-3acb-47c7-a8df-230a485ed6f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for k in range(1, 11):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_test, knn.predict(X_test))\n",
    "    print(f\"k={k}, Accuracy={acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3c597ea-3d5c-48cc-8b44-0c3fa0ad744b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 🌳 What Is a Decision Tree?\n",
    "A Decision Tree is a flowchart-like structure used for classification and regression. It splits the data based on feature values to make decisions, forming a tree of rules.\n",
    "\n",
    "🔍 How It Works:\n",
    "At each node, the algorithm chooses the best feature and threshold to split the data.\n",
    "\n",
    "Splitting continues until a stopping condition is met (e.g., max depth, pure leaf nodes).\n",
    "\n",
    "Predictions are made by tracing the path from root to leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7563a012-83d6-4bfa-a967-e51a113ec4f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = load_iris()\n",
    "x=iris.data\n",
    "y=iris.target\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)\n",
    "model=DecisionTreeClassifier(max_depth=3,random_state=42)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b61c99c0-b08b-4ddc-a286-10553ae315ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b1a8e20-1782-4c4f-90df-743a9af3530c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "df = pd.DataFrame(x, columns=feature_names)\n",
    "df['target'] = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9963d6c9-13eb-4258-9fb8-ffd20665441b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i, target_name in enumerate(target_names):\n",
    "    plt.scatter(\n",
    "        df[df['target'] == i]['petal length (cm)'],\n",
    "        df[df['target'] == i]['petal width (cm)'],\n",
    "        label=target_name,\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "plt.xlabel('Petal Length (cm)')\n",
    "plt.ylabel('Petal Width (cm)')\n",
    "plt.title('Iris Dataset: Petal Length vs Width')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01caca7c-f0f4-45cb-9710-84eeabc752b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49ad5e66-f261-428c-8bba-616e7a19ae34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(model, feature_names=feature_names, class_names=target_names.tolist(), filled=True)\n",
    "plt.title(\"Decision Tree for Iris Dataset\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ClassificationML",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
